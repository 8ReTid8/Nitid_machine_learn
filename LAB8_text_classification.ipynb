{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# 1."
      ],
      "metadata": {
        "id": "wIt9Ae6Lysmd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kZvaeDCTYylo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e9719e3-03ae-4154-88aa-d56be376fefb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cat': 4,\n",
              " 'dog': 8,\n",
              " 'sat': 34,\n",
              " 'mat': 21,\n",
              " 'cat dog': 5,\n",
              " 'dog sat': 10,\n",
              " 'sat mat': 35,\n",
              " 'stock': 36,\n",
              " 'market': 19,\n",
              " 'reached': 30,\n",
              " 'time': 40,\n",
              " 'high': 15,\n",
              " 'today': 42,\n",
              " 'stock market': 37,\n",
              " 'market reached': 20,\n",
              " 'reached time': 31,\n",
              " 'time high': 41,\n",
              " 'high today': 16,\n",
              " 'barked': 2,\n",
              " 'stranger': 38,\n",
              " 'park': 27,\n",
              " 'dog barked': 9,\n",
              " 'barked stranger': 3,\n",
              " 'stranger park': 39,\n",
              " 'crytocurrency': 6,\n",
              " 'popular': 28,\n",
              " 'investment': 17,\n",
              " 'option': 22,\n",
              " 'recent': 32,\n",
              " 'years': 43,\n",
              " 'crytocurrency popular': 7,\n",
              " 'popular investment': 29,\n",
              " 'investment option': 18,\n",
              " 'option recent': 23,\n",
              " 'recent years': 33,\n",
              " 'apples': 0,\n",
              " 'oranges': 25,\n",
              " 'healthy': 13,\n",
              " 'fruit': 11,\n",
              " 'options': 24,\n",
              " 'apples oranges': 1,\n",
              " 'oranges healthy': 26,\n",
              " 'healthy fruit': 14,\n",
              " 'fruit options': 12}"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "documents = ['The cat and dog sat on the mat.',\n",
        "             'The stock market reached an all-time high today.',\n",
        "             'The dog barked at the stranger in the park.',\n",
        "             'Crytocurrency has become a popular investment option in recent years.',\n",
        "             'Apples and oranges are both healthy fruit options.']\n",
        "label = ['Animal','Finance','Animal','Finance','Food']\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "count_vector = CountVectorizer(stop_words = 'english',\n",
        "                               ngram_range=(1,2))\n",
        "count_vector.fit(documents)\n",
        "count_vector.vocabulary_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9N3j_ZqayrVt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 2."
      ],
      "metadata": {
        "id": "Vd7ohhAvrSdU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "terms = count_vector.get_feature_names_out()\n",
        "doc_array = count_vector.transform(documents).toarray()\n",
        "doc_lenth = doc_array.sum(axis=1)\n",
        "tf_mat = doc_array / doc_lenth.reshape(-1,1)\n",
        "word = count_vector.vocabulary_\n",
        "print(tf_mat)\n",
        "print(tf_mat[2][word.get('dog')])\n",
        "print(terms)\n",
        "print(doc_array.shape)\n",
        "print(documents[2] ,\"->\", doc_array[2][8])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ek_MCdqXoX8P",
        "outputId": "ef514194-32c0-44e2-d4e1-088e5fc4b73c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.         0.         0.         0.         0.14285714 0.14285714\n",
            "  0.         0.         0.14285714 0.         0.14285714 0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.14285714 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.14285714 0.14285714\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.09090909 0.09090909 0.\n",
            "  0.         0.09090909 0.09090909 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.09090909 0.09090909 0.         0.         0.         0.\n",
            "  0.09090909 0.09090909 0.         0.         0.09090909 0.09090909\n",
            "  0.09090909 0.        ]\n",
            " [0.         0.         0.14285714 0.14285714 0.         0.\n",
            "  0.         0.         0.14285714 0.14285714 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.14285714 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.14285714 0.14285714 0.         0.\n",
            "  0.         0.        ]\n",
            " [0.         0.         0.         0.         0.         0.\n",
            "  0.09090909 0.09090909 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.09090909\n",
            "  0.09090909 0.         0.         0.         0.09090909 0.09090909\n",
            "  0.         0.         0.         0.         0.09090909 0.09090909\n",
            "  0.         0.         0.09090909 0.09090909 0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.09090909]\n",
            " [0.11111111 0.11111111 0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.11111111\n",
            "  0.11111111 0.11111111 0.11111111 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.11111111 0.11111111 0.11111111 0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.         0.         0.         0.         0.\n",
            "  0.         0.        ]]\n",
            "0.14285714285714285\n",
            "['apples' 'apples oranges' 'barked' 'barked stranger' 'cat' 'cat dog'\n",
            " 'crytocurrency' 'crytocurrency popular' 'dog' 'dog barked' 'dog sat'\n",
            " 'fruit' 'fruit options' 'healthy' 'healthy fruit' 'high' 'high today'\n",
            " 'investment' 'investment option' 'market' 'market reached' 'mat' 'option'\n",
            " 'option recent' 'options' 'oranges' 'oranges healthy' 'park' 'popular'\n",
            " 'popular investment' 'reached' 'reached time' 'recent' 'recent years'\n",
            " 'sat' 'sat mat' 'stock' 'stock market' 'stranger' 'stranger park' 'time'\n",
            " 'time high' 'today' 'years']\n",
            "(5, 44)\n",
            "The dog barked at the stranger in the park. -> 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "# 3."
      ],
      "metadata": {
        "id": "MpGHUNzRmWXC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "8q4OumKHvOo0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "softmax = LogisticRegression()\n",
        "softmax.fit(doc_array,label)\n",
        "pre = softmax.predict_proba(doc_array)\n",
        "print(pre)\n",
        "print(softmax.classes_)\n",
        "# print(accuracy_score(pre,label))"
      ],
      "metadata": {
        "id": "F42gfl5JrXdT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1afa5980-6c95-41cc-96bc-46b6a1a78a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0.85123481 0.09152153 0.05724366]\n",
            " [0.09103509 0.85897216 0.04999275]\n",
            " [0.85123481 0.09152153 0.05724366]\n",
            " [0.09103509 0.85897216 0.04999275]\n",
            " [0.11550163 0.09877078 0.78572759]]\n",
            "['Animal' 'Finance' 'Food']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4."
      ],
      "metadata": {
        "id": "rgJBCs0QrBks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import A\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "doc_ver1 = ['fruit options']\n",
        "doc_ver1 = count_vector.transform(doc_ver1).toarray()\n",
        "clf = CategoricalNB()\n",
        "clf.fit(doc_array,label)\n",
        "y_label = clf.predict(doc_array)\n",
        "A,F,Fo = clf.predict_proba(doc_ver1)[0]\n",
        "print(\"proba A \",A)\n",
        "print(\"proba F \",F)\n",
        "print(\"proba Fo \",Fo)\n",
        "print(y_label)"
      ],
      "metadata": {
        "id": "C0nXb9KDnk2T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "76c7a66a-10b7-4f2e-8dcb-63d04c822cba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "proba A  0.6609471520680834\n",
            "proba F  0.03438550443111914\n",
            "proba Fo  0.304667343500799\n",
            "['Animal' 'Finance' 'Animal' 'Finance' 'Food']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "target_names=['Animal' 'Finance' 'Food']\n",
        "print(classification_report(label,y_label))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kLB3m53uZbC_",
        "outputId": "1d20a0cc-7e02-4828-d64b-d15ab3d0a718"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Animal       1.00      1.00      1.00         2\n",
            "     Finance       1.00      1.00      1.00         2\n",
            "        Food       1.00      1.00      1.00         1\n",
            "\n",
            "    accuracy                           1.00         5\n",
            "   macro avg       1.00      1.00      1.00         5\n",
            "weighted avg       1.00      1.00      1.00         5\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5."
      ],
      "metadata": {
        "id": "zy7WE9Idf8rW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import subprocess\n",
        "! curl https://raw.githubusercontent.com/PyThaiNLP/thai-sentiment-analysis-dataset/master/review_shopping.csv > file.txt\n",
        "document2 = subprocess.getoutput(\"cut -d'\\t' -f1 < file.txt\")\n",
        "document2 = document2.split(\"\\n\")\n",
        "label2 = subprocess.getoutput(\"cut -d'\\t' -f2 < file.txt\")\n",
        "label2 = label2.split(\"\\n\")\n",
        "len(label2)\n",
        "label2.count('neg')\n",
        "# print(document2)\n",
        "# print(label2)\n",
        "\n",
        "# document2 = [x.replace(' ', '') for x in document2]\n",
        "document2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3e1NW3pOf-u9",
        "outputId": "b4ea272b-208d-4214-d1c5-3c6f1a9fb4e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 19211  100 19211    0     0  36277      0 --:--:-- --:--:-- --:--:-- 36247\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['เกลียด ชอบหลอกให้สั่งซื้อ ที่ไหนได้ไม่มีสิ้นค้า',\n",
              " 'สินค้าด้อยคุณภาพ',\n",
              " 'สินค้าหมดทำไมไม่แจ้งขึ้นว่าหมดอะ.กดใส่ตะกร้าไปเถอะ.เซ็งเรย',\n",
              " 'อย่าทำแบบนี้กับใครอีกนะค่ะแย่มากค่ะ',\n",
              " 'คือเเบบผิดหวังมาก เเย่ที่สุดได้ของมาฝาเเตก เเตกนิดหน่อยไม่ว่าเเตกเยอะมาก ครั้งเดียวพอจบเเยก😢',\n",
              " 'ส่งช้าจัง รอนานมาก ยกเลิกก้อไม่ได้',\n",
              " 'แย่มากกกกกกค่ะ เอาของพังมาให้ฉุนมาดค่ะไม่พอใจเป็นอย่างมากค่ะ. ส่งของ ก็ไม่ได้ใบเสร็จ. ไม่ไหวจะเคลียร์',\n",
              " 'ไม่แนะนำซื้อมาใช้ได้วันเดียวใช้ไม่ได้แล้ว',\n",
              " 'แย่ๆสั่งสินค้าไปหลายวันแล้วไม่ส่งให้สักทีเหนื่อยกับการรอคอย',\n",
              " 'เสียความรู้สึกอย่างมาก สวยแต่ในรูปใส่ได้ครั้งเดียว ไม่ดี',\n",
              " 'ยอดเยี่ยมค่ะ ราคาเหมาะสม บอกต่อได้เลยค่ะ',\n",
              " 'สวยค่ะ เหมือนในรูปเลย ชอบค่ะ ส่งของไวมากก',\n",
              " 'ใช้ดีค่ะหน้านุ่มและขาวขึ้น',\n",
              " 'จัดส่งเร็วมาก สะดวกดี ของจริงขนาดใหญ่กว่าที่คิดไว้ แต่ใช้งานได้ดี',\n",
              " 'ชอบสินค้ามาก ไม่ผิดหวังที่รอ สวยยังบรรจุภัณฑ์คับ',\n",
              " 'สินค้าส่งรวดเร็ว พอใจในสินค้าครับ',\n",
              " 'สินค้าคุณภาพดี แข็งแรง เสียงดี เด็กๆ ชอบ และยังส่งเร็วด้วยค่ะ',\n",
              " 'ราคากับคุณภาพของสินค้ามีความเหมาะสม ใช้งานง่าย',\n",
              " 'ส่งของไว ห่อพัสดุดี  ของใช้งานเยี่ยม',\n",
              " 'สวยค่ะ การจัดส่งก็รวดเร็วดีค่ะ',\n",
              " 'ใช้เดือนเดียวพังแย่ๆมากๆ',\n",
              " 'เสียใจความรู้สึกมากกระเป๋าบางมากไม่ตรงกะแบบสินค้าที่ลงการแพ็คของส่งก็แย่เอาถุงดำที่ใส่ขยะแถมสกปรกมากทำไมไม่ตรวจสอบก่อนส่งถึงมือลูกค้าเราไปซื้อของคุณนะไม่ได้ไปขอฟรีๆปรับปรุงด่วน!!!! ',\n",
              " 'การส่งของแย่มาก ขนาดตะโกนว่ารอเดี๋ยว ยังโยนสินค้าข้ามรั้ว ถ้าโน้ตบุคเสียหายจะทำยังไง',\n",
              " 'ใช้ในรถระบบเสีย พังใช้ต่อไม่ได้',\n",
              " 'ผิดหวัง ลบไม่ออก',\n",
              " 'หมดอายุแล้วไม่ควรเอามาลงขายค่ะเสียใจผิดหวังมากๆค่ะกว่าจะหมดแพงด้วยนะ',\n",
              " 'ส่งช้ามาก ตอนนี้ยังไม่ได้ของ',\n",
              " 'ได้รับของแล้วผิดหวังมาก ไม่ดีเลยค่ะ',\n",
              " 'สินค้าไม่มีคุณภาพสายกางเกงไม่เท่ากัน',\n",
              " 'ช้าสุดๆรอจนรำคาญละ',\n",
              " 'คุณภาพคุ้มค่าครับ',\n",
              " 'ส่งเร็วดี ใช้ดีคุ้มมาก ราคาถูก',\n",
              " 'ได้รับสินค้าเร็วค่ะ และสินค้าก็มีคุณภาพ สวมใส่สบายตัวมากๆๆ เลยค่ะ',\n",
              " 'ได้รับของเร็วมาก.. แถมสินค้าได้ตามต้องการสวยมาก',\n",
              " 'รับประทานดีอยู่นะครับ มองเห็นความเปลี่ยนแปลงของร่างกาย ทานแล้วรู้สึกว่าดีนะ',\n",
              " 'ใช้ได้ดีเหมาะกับราคานี้ ก็สรุปว่าดีครับ',\n",
              " 'สินค้าใช้แล้วดีมากไม่ทำให้ลูกแพ้เลยแถมราคาถูกกว่าในห้างและตามร้านค้าอีก',\n",
              " 'ใช้งานดีมากส่งของก็เร็วของครับ',\n",
              " 'ส่งไวมาก สั่งตอนเย็น ตอนเช้าได้แล้ว สินค้าแพ็คมาดีมาก ใช้งานได้ปกติไม่มีปัญหาอะไร ถือว่าคุ้มค่าสุดๆครับ',\n",
              " 'วัสดุค่อนข้างดีนับว่าคุ้มราคาครับ',\n",
              " 'สินค้าไม่เหมือนในรูป ผิดหวังมาก เย็บไม่ดีเลย',\n",
              " 'ใช้แล้วสิวขึ้นเต็มเลยไม่รู้แพ้รึเปล่า....เซ็งเลยเหลือตั้งเยอะเสียดายมาก',\n",
              " 'คุณภาพแย่มากใช้งานไม่ได้แม้แต่ครั้งเดียว',\n",
              " 'ผิดหวังมาก ไม่แนะนำให้ใช้ค่ะ',\n",
              " 'สรุปแพงกว่าท้องตลาดคะแย่มากเสียความ',\n",
              " 'รู้สึกผิดหวังมาก ไม่ใช่แบบที่หวังไว้เลยย',\n",
              " 'แย่มากๆๆๆๆ ไม่ส่งของแถมมาให้ตามที่โฆษณา ',\n",
              " 'งานไม่ค่อยดี ไม่สมกับราคา',\n",
              " 'แย่มากเลย นมใกล้หมดอายุ ครั้งนี้ครั้งสุดท้ายนะคะที่จะสั่ง',\n",
              " 'ใช้ได้ไม่กี่เดือนก็พังล่ะยังใช้ไม่คุ้มกับราคาที่ซื้อมาเลย',\n",
              " 'ใส่สบายสั่งหลายรอบแล้วจร้าาา',\n",
              " 'ส่งของรวดเร็วดี คุณภาพใช้ได้ค่ะ',\n",
              " 'ใช้งานได้ดีราคาไม่แพงมาก',\n",
              " 'ชอบที่ส่งเร็วมากครับ ทันใจดีจิงๆ',\n",
              " 'รับของไว พนักงานส่งของดีมาก คุณภาพคุ้มราคา',\n",
              " 'ดีครับ คุ้มค่าคุ้มราคา น่าจะใช้งานได้ทนทานมือใหม่น่าเอามาใช้ครับ',\n",
              " 'คุณภาพพอใช้ได้  ดูบอบบางจัง ต้องดูระยะการใช้งานระยะยาวค่ะรวม ๆ ถือว่าโอเคค่ะ',\n",
              " 'สินค้าแพคอย่างดี ที่สำคัญส่งขอเร็วมาก คิดว่าจะได้ช้าเสียอีก',\n",
              " 'ส่งของไวมาก แต่ราคาขึ้นลงบ่อยมา ต้องเข้ามาเช็คราคาบ่อยๆ ว่าวันไหนจะราคาถูก แต่คุ้มแน่นอนค่ะ เลือกซื้ออันนี้ไม่ผิดหวังค่ะ',\n",
              " 'ได้รับของเร็วมาก กระทะร้อนเร็ว ทำอาหารได้หลายอย่างเลยค่ะ ชอบมาก',\n",
              " 'เสียดายที่ไว้ใจใช้บริการผิดหวังมาก เอาสินค้าของคุณคือไปเถอะ แล้วคืนเงินให้เรา สั่งของก็บ่อยต่อไปไม่สั่งแล้ว แย่มากๆๆๆๆๆๆๆๆๆๆๆๆๆๆ',\n",
              " 'แย่มากอย่าสั่งนะ',\n",
              " 'แย่มาก รูปดูสวยหรูดีนะ แต่มาเจอของจริงนี่แย่สุดๆ สินค้าไม่สมกับราคาเลย ',\n",
              " 'แย่มากเสียดายเงิน',\n",
              " 'สินค้ามีรอยตำหนิ เป็นรอยง่าย ',\n",
              " 'สินค้าคุณภาพแย่มาก วัสดุเหมือนหมดอายุแล้ว',\n",
              " 'สินค้าส่งมาแตกหัก ยังไม่ได้ประกอบเลย เสียความรู้สึก',\n",
              " 'ซื้อแล้วผิดหวังสินค้าไม่มีคุณภาพ',\n",
              " 'แย่มาก บิดน้ำไม่แห้ง เสียดายตังมาก',\n",
              " 'ตกใจมาก โคตรแย่ ก่อนหน้านี้ใช้ดี ชอบมาก ปลอดภัยดี ตอนระเบิดมีกลิ่นไหม้กับประกายไฟ ไม่เป็นแผลแต่เป็นดำๆ ที่มือ แสบเล็กน้อย',\n",
              " 'สินค้าใช้ดีสีสดใช้จนถึงทุกวันนี้',\n",
              " 'ร้านนี้ ขายสินค้าตรงตามประกาศ ส่งตามกำหนด สินค้าใช้งานดี',\n",
              " 'ถูกกว่าในห้างเยอะเลยครับ ภาพชัด สินค้าใหม่ พนักงานบริการดีมาก สั่งสินค้ากับลาซาด้าไม่เคยผิดหวังเลยครับ',\n",
              " 'แรงดี หน้าจอใหญ่ ส่งของเร็ว พอใจครับ',\n",
              " 'จอใหญ่มาก คุณภาพเสียง ชัดเจนดีมาก โดยรวมแล้วคุ้มค่ามาก',\n",
              " 'พกพาสะดวก ได้ของเร็ว',\n",
              " 'โอเคมาก เป็นอย่างที่คาดหวังไว้ เยี่ยม',\n",
              " 'ได้สินค้าภายในสองวัน OK นะครับ สมราคา ใช้งานได้ปกติ',\n",
              " 'ดีมากๆๆคะ ได้เร็ว แพ๊คดี สินค้าสภาพดี ราคาถูก ไม่ต้องไปเดินช๊อปเอง ดีคะ',\n",
              " 'ส่งของรวดเร็วมาก สินค้าใหม่ด้วย โดยรวมให้คะแนนเต็มครับ',\n",
              " 'ไม่พึงพอใจเลย  สินค้าผลิตจากพลาสติกด้อยคุณภาพ  ก๊องแก๊งมาก',\n",
              " 'แพ็คของไม่ดีมากเลยครับข้างในกล่องฉีกขาดไม่สวยเลย',\n",
              " 'คุณภาพสินค้าไม่น่าประทับใจ',\n",
              " 'วัสดุแย่ ขาดง่าย เสียดายเงิน',\n",
              " 'อย่าขายเลย ยกเลิกโปรนี้เถอะ เสียความรู้สึก ดูมาหลายเดือนละ',\n",
              " 'แบตแย่มากค่ะ หมดเร็วมาก รับประกันไม่ได้ชวยอะไรเลย ',\n",
              " 'เห็นแล้วรู้สึกแย่ ไม่มั่นใจในสินค้าร้านนี้',\n",
              " 'คุณภาพแย่มากค่ะ ใช้ครั้งแรกมีกลิ่นไหม้ออกมาเลยแถมข้าวไม่สุกด้วย',\n",
              " 'เสียเวลามากๆ กว่าจะทำเรื่องคืนเงินได้ ของก็ต้องใช้ ต้องไปซื้อใหม่ เสียเงินซ้ำอีก ระบบการทำงานแย่มาก มันเหมือนกันมากเลยหรือ ส่งผิดรุ่นได้',\n",
              " 'หลอกลวง ต้มตุ๋น เอาของปลอมมาขาย ร้านโจร',\n",
              " 'ส่งเร็วทันใช้ตามความต้องการ',\n",
              " 'เนื้อผ้าดีแต่ไม่หนา เซ็กซี่ดีแต่ไม่โป๊ะ คุณภาพสมกับราคา',\n",
              " 'ง่ายดีไม่ต้องหาซื้อให้ยุ่งยาก',\n",
              " 'สมราคาค่ะ ภาพชัดเจน เทียบกับยี่ห้ออื่นราคาถูกกว่า',\n",
              " 'สวยมาใช้งานง่ายมากที่สำคัญส่งเร็วมาก',\n",
              " 'เสียงดี ส่งเร็ว ราคานี้คุ้มครับ ',\n",
              " 'ใช้ดียังไม่มีปัญหาอะไรค่ะชอบมาก',\n",
              " 'สเป็คถือว่าโอเครเลยคับ ไหลลื่นดีไม่มีสดุด สมกับราคา และคุ้มค่ามากๆเลย',\n",
              " 'ใช้ดีส่งของไว มากเจ้านี้  วัสดุคุณภาพจริงจริง',\n",
              " 'แพคของเรียบร้อยดีค่ะ ส่งเร็ว ไว้จะสั่งอีกนะคะ☺',\n",
              " 'เกรดต่ำเหมือนกับว่าเอาของถูกๆมาคละกัน',\n",
              " 'สั่งซื้อแล้วอยู่ดีๆมายกเลิก เสียความรู้สึกเลยครับ',\n",
              " 'ไม่เป็นไปตามที่โฆษณา ส่งสินค้าไม่ตรงตามกำหนด เมื่อสินค้ามีปัญหาไม่รับผิดชอบใด ',\n",
              " 'ไม่ซึมซับลูกอับชื้นโฆษณาเกินจริงเสียเงินฟรีไม่คุ้มแย่มาก',\n",
              " 'ไม่มีคู่มือ แย่มากครับ กล่องก็ไม่มี ใส่ถุงมาให้ ทุเรศมากครับ',\n",
              " 'สินค้าไม่ตรงปก ของคุณภาพร้อยกว่าบาท แย่ๆ',\n",
              " 'แย่มากๆสั่งของจ่ายเงิน แต่ไม่ได้ของ!',\n",
              " 'ใช้ได้แป็บเดียวพังแล้ว',\n",
              " 'สินค้าชำรุด ส่งมาถึงแกะดู สินค้าแตก',\n",
              " 'ซื้อมายังไม่ทันเล่นเลยพังซะแล้ว',\n",
              " 'ผ้านิ่ม เด้งๆ ดีกว่าที่คิดไว้ ชอบคะ',\n",
              " 'โอเครค่ะได้สินค้าตามรูปผ้าใส่สบาย',\n",
              " 'เสื้อสวยถูกใจค่ะส่งเร็วทันใจดี',\n",
              " 'คุณภาพเหมาะสมกับราคา ใช้งานOK ต่อดูภาพจากคอมชัดมาก จัดส่งเร็วดี',\n",
              " 'เนื้อผ้าดีมากๆๆๆๆเกินราคา กำลังจะสั่งเพิ่มอีก ช้าหน่อยแต่ได้มาไม่ผิดหวังเลยค่ะ',\n",
              " 'ใช้ดี ราคาไม่แพงเกินค่ะ พอใจมาก',\n",
              " 'ใช้ดีมากค่ะ ช่วยให้หน้าตึงขึ้น หน้าไม่เหี่ยว  เราใช้มาตลอดค่ะ สั่งอีกแน่',\n",
              " 'จากการพิสูจน์เป็นหนังแท้ เลือกไม่ผิด งานเย็บละเอียด ชอบครับ ',\n",
              " 'แพ็คสินค้าดี สินค้าคุณภาพ สมราคา แฟนประทับใจครับ',\n",
              " 'ส่งของได้เร็วมาก สินค้าใช้ได้ดีไม่มีปัญหา คุ้ม',\n",
              " 'เสียความรู้สึกค่ะมาไม่ตรงที่สั่ง',\n",
              " 'มันผิดพลาดอะไรหรือลงรูปเพื่อหลอกให้คนสั่งซื้ออธิบายหน่อย',\n",
              " 'สินค้าคุณภาพไม่ค่อยดี',\n",
              " 'สินค้ามีตำหนิ แย่มากๆ ไม่ไหวๆเลย ถ้ามีตำหนิก็บอกด้วยครับ จะได้ทำใจก่อนซื้อ',\n",
              " 'เปราะบางมากความแข็งแรงน้อย มันง่ายต่อการแตกหัก',\n",
              " 'ขนส่งก็ช้าสินค้ามีตำหนิแพ็คสินค้าไม่ดีมีรอยบุบ',\n",
              " 'สินค้าเหมือนของปลอม เนื่อครีมเหมือนซอง 10 บาท บรรจุภัณฑ์เหมือนก๊อปมา ไม่เหมือนของจริงในห้างเลย เสียดายตังค์ ซื้อมาทิ้ง',\n",
              " 'รายการไม่ดี ที่จับไม่ดีและสั้น']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6."
      ],
      "metadata": {
        "id": "F8bqDpLpplCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install PyThaiNLP\n",
        "from pythainlp.corpus.common import thai_stopwords\n",
        "from pythainlp import  word_tokenize\n",
        "from pythainlp.util import normalize\n",
        "thai = list(thai_stopwords())\n",
        "def text_process(text):\n",
        "  prunct =  [',','?','.',';',':','!','ๆ','ฯ']\n",
        "  clean = [x for x in text if x not in prunct]\n",
        "  clean = ''.join(clean)\n",
        "  clean = word_tokenize(clean)\n",
        "  clean = [normalize(x) for x in clean]\n",
        "  final = [x for x in clean if x not in thai]\n",
        "  final = ''.join(final)\n",
        "  return final\n",
        "  # return word_tokenize(text)\n",
        "\n",
        "\n",
        "text_process_value = text_process(document2)\n",
        "# text_process_value = [text_process(doc) for doc in document2]\n",
        "print(text_process_value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "mAC_BxkhmDQz",
        "outputId": "6ad74b5b-6ca7-4a26-876a-a3374ca7967f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyThaiNLP in /usr/local/lib/python3.10/dist-packages (5.0.4)\n",
            "Requirement already satisfied: requests>=2.22.0 in /usr/local/lib/python3.10/dist-packages (from PyThaiNLP) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->PyThaiNLP) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->PyThaiNLP) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->PyThaiNLP) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.22.0->PyThaiNLP) (2024.8.30)\n",
            "เกลียดชอบหลอกสั่งซื้อที่ไหนได้ค้าสินค้าด้อยคุณภาพสินค้าแจ้งอะ.กดใส่ตะกร้า.เซ็งเรยอย่าทำแบบนี้แย่มากผิดหวังแย่ฝาเเตกเเตกเเตกจบเเยก😢รอยกเลิกก้อแย่กกกกกกพังฉุนมาดพอใจเป็นอย่างมาก.ใบเสร็จ.ไหวจะเคลียร์แนะนำซื้อใช้ได้ใช้ไม่ได้แย่สั่งสินค้าสักทีเหนื่อยการรอคอยเสียความรู้สึกสวยรูปใส่ดียอดเยี่ยมราคาเหมาะสมบอกต่อสวยเหมือนรูปชอบไวกกดีหน้านุ่มขาวจัดส่งสะดวกดีของจริงขนาดใหญ่ใช้งานได้ดีชอบสินค้าผิดหวังรอสวยบรรจุภัณฑ์คับสินค้าส่งพอใจสินค้าสินค้าคุณภาพดีแข็งแรงเสียงดีเด็กชอบราคาคุณภาพสินค้าความเหมาะสมใช้งานไวห่อพัสดุดีใช้งานเยี่ยมสวยการจัดส่งดีเดือนพังแย่เสียใจความรู้สึกกระเป๋ากะสินค้าแพ็คแย่ถุงดำใส่ขยะแถมสกปรกตรวจสอบมือลูกค้าซื้อฟรีปรับปรุงด่วน!!!!แย่มากขนาดตะโกนรอเดี๋ยวโยนสินค้าข้ามรั้วโน้ตบุคเสียหายทำรถระบบพังผิดหวังลบหมดอายุขายเสียใจผิดหวังแพงตอนนี้ผิดหวังดีสินค้าคุณภาพสายกางเกงๆรอจนรำคาญคุณภาพคุ้มค่าดีดีคุ้มราคาสินค้าสินค้าคุณภาพสวมใส่ตัวๆๆก..แถมสินค้าต้องการสวยรับประทานดีมองเห็นความเปลี่ยนแปลงร่างกายทานรู้สึกดีได้ดีเหมาะกับราคาสรุปดีสินค้าใช้แล้วดีมากลูกแพ้แถมราคาห้างร้านค้าใช้งานดีมากไวสั่งตอนเย็นตอนเช้าสินค้าแพ็คดีมากใช้งานปกติมีปัญหาคุ้มค่าวัสดุดีนับว่าคุ้มราคาสินค้าเหมือนรูปผิดหวังเย็บดีใช้แล้วสิวเต็มรู้แพ้รึเปล่า....เซ็งเสียดายคุณภาพแย่มากใช้งานผิดหวังแนะนำสรุปแพงท้องตลาดแย่มากเสียความรู้สึกผิดหวังที่หวังยแย่มากๆๆๆๆของแถมโฆษณางานดีสมราคาแย่มากนมหมดอายุครั้งสุดท้ายนะคะที่จะสั่งใช้ได้กี่เดือนพังล่ะคุ้มราคาที่ซื้อใส่สั่งรอบจร้าาดีคุณภาพใช้ได้ใช้งานได้ดีราคาแพงชอบใจดีจิงๆไวพนักงานดีมากคุณภาพคุ้มราคาดีคุ้มค่าคุ้มราคาใช้งานทนทานมือใหม่คุณภาพพอใช้ได้ดูบอบบางดูการใช้งานระยะยาวโอเคสินค้าแพคอย่างดีไวราคาเข้ามาเช็คราคาไหนจะราคาคุ้มแน่นอนเลือกซื้ออันนี้ผิดหวังกระทะร้อนทำอาหารหลายอย่างชอบเสียดายไว้ใจบริการผิดหวังสินค้าคืนเงินสั่งต่อไปสั่งแย่มากๆๆๆๆๆๆๆๆๆๆๆๆๆๆแย่มากอย่าสั่งแย่มากรูปดูสวยหรูดีเจอของจริงแย่สินค้าสมราคาแย่มากเสียดายเงินสินค้ารอยตำหนิรอยสินค้าคุณภาพแย่มากวัสดุเหมือนหมดอายุสินค้าส่งแตกหักเสียความรู้สึกซื้อผิดหวังสินค้าคุณภาพแย่มากบิดน้ำแห้งเสียดายตังตกใจโคตรแย่ดีชอบปลอดภัยดีตอนระเบิดกลิ่นไหม้ประกายไฟเป็นแผลดำมือแสบสินค้าดีสีสดร้านขายสินค้าประกาศตามกำหนดสินค้าใช้งานดีห้างภาพชัดสินค้าพนักงานบริการดีมากสั่งสินค้าลาซาด้าผิดหวังแรงดีหน้าจอพอใจจอคุณภาพเสียงชัดเจนดีมากโดยรวมคุ้มค่าพกพาสะดวกโอเคคาดหวังเยี่ยมสินค้าสองOKสมราคาใช้งานปกติดีมากๆๆแพ๊คดีสินค้าสภาพดีราคาไม่ต้องเดินช๊อปดีสินค้าโดยรวมคะแนนเต็มพึงพอใจสินค้าผลิตพลาสติกด้อยคุณภาพก๊องแก๊งแพ็คดีมากข้างในกล่องฉีกขาดสวยคุณภาพสินค้าน่าประทับใจวัสดุแย่เสียดายเงินอย่าขายยกเลิกโปรเสียความรู้สึกดูเดือนแบตแย่มากรับประกันชวยรู้สึกแย่มั่นใจสินค้าร้านคุณภาพแย่มากครั้งแรกกลิ่นไหม้ออกมาแถมข้าวสุกเสียเวลาทำเรื่องคืนเงินได้ซื้อเสียเงินซ้ำระบบการทำงานแย่มากเหมือนกันรุ่นหลอกลวงต้มตุ๋นของปลอมขายร้านโจรความต้องการเนื้อผ้าดีแต่หนาเซ็กซี่ดีแต่โป๊ะคุณภาพสมราคาดีต้องหาซื้อยุ่งยากสมราคาภาพชัดเจนเทียบยี่ห้อราคาสวยใช้งานเสียงดีราคาคุ้มดีมีปัญหาชอบสเป็คโอเครคับไหลลื่นดีสดุดสมราคาคุ้มค่าดีไวเจ้าวัสดุภาพจริงแพคเรียบร้อยดีสั่งนะคะ☺เกรดต่ำเหมือนกับคละสั่งซื้ออยู่ดีๆยกเลิกเสียความรู้สึกเป็นไปโฆษณาส่งสินค้าตามกำหนดสินค้ามีปัญหารับผิดชอบใดซึมซับลูกอับชื้นโฆษณาเสียเงินฟรีคุ้มแย่มากคู่มือแย่มากกล่องใส่ถุงทุเรศสินค้าปกคุณภาพร้อยบาทแย่แย่มากสั่งจ่ายเงิน!ใช้ได้แป็บพังสินค้าชำรุดมาถึงแกะดูสินค้าแตกซื้อมายังเล่นพังผ้านิ่มเด้งดีกว่าชอบโอเครสินค้ารูปผ้าใส่เสื้อสวยถูกใจใจดีคุณภาพเหมาะสมราคาใช้งานOKดูภาพคอมชัดจัดส่งดีเนื้อผ้าดีมากๆๆๆๆราคาสั่งผิดหวังดีราคาแพงพอใจดีมากหน้าตึงหน้าเหี่ยวสั่งแน่การพิสูจน์หนังเลือกงานเย็บละเอียดชอบแพ็คสินค้าดีสินค้าคุณภาพสมราคาแฟนประทับใจสินค้าได้ดีมีปัญหาคุ้มเสียความรู้สึกสั่งผิดพลาดรูปหลอกคนสั่งซื้ออธิบายสินค้าคุณภาพดีสินค้ามีตำหนิแย่มากไหวมีตำหนิทำใจซื้อเปราะบางความแข็งแรงแตกหักขนส่งสินค้ามีตำหนิแพ็คสินค้าดีรอยบุบสินค้าเหมือนของปลอมเนื่อครีมเหมือนซอง10บาทบรรจุภัณฑ์เหมือนก๊อปเหมือนของจริงห้างเสียดายตังค์ซื้อทิ้งรายการดีที่จับดี\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "vectorizer = TfidfVectorizer(stop_words=thai,\n",
        "                             tokenizer=text_process,\n",
        "                             ngram_range=(1,2),\n",
        "                             min_df=2)\n",
        "vectorizer.fit(document2)\n",
        "vectorizer.vocabulary_\n",
        "terms = vectorizer.get_feature_names_out()\n",
        "doc_array2 = vectorizer.transform(document2).toarray()\n",
        "\n",
        "\n",
        "print(doc_array2.shape)\n",
        "print(doc_array2)\n",
        "print(terms)\n",
        "print(len(vectorizer.vocabulary_))\n",
        "print(vectorizer.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L08kGiqNtim7",
        "outputId": "3dd7becb-bd7f-446d-acd0-7e4f92fd9b95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ก', 'ง', 'จ', 'ช', 'ด', 'ต', 'ถ', 'ท', 'น', 'บ', 'ป', 'พ', 'ม', 'ย', 'ร', 'ล', 'ว', 'ส', 'ห', 'อ', 'ะ', 'ั', 'า', 'ำ', 'ิ', 'ี', 'ึ', 'ื', 'ู', 'เ', 'แ', 'โ', 'ใ', 'ไ', '็', '่', '้', '๋', '์', '\\ufeff'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 510)\n",
            "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.0776411  0.         0.14753657]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
            "['k' 'o' 'o k' 'ก' 'ก ก' 'ก ข' 'ก ค' 'ก ง' 'ก ซ' 'ก ด' 'ก ต' 'ก น' 'ก พ'\n",
            " 'ก ร' 'ก ล' 'ก ว' 'ก ส' 'ก ห' 'ก อ' 'ก ะ' 'ก ั' 'ก า' 'ก ำ' 'ก เ' 'ก แ'\n",
            " 'ก โ' 'ก ใ' 'ก ๊' 'ข' 'ข น' 'ข อ' 'ข า' 'ข ็' 'ข ้' 'ค' 'ค ด' 'ค ร' 'ค ล'\n",
            " 'ค ว' 'ค ส' 'ค อ' 'ค ะ' 'ค ั' 'ค า' 'ค ื' 'ค ุ' 'ค เ' 'ค ่' 'ค ้' 'ฆ'\n",
            " 'ฆ ษ' 'ง' 'ง ก' 'ง ค' 'ง จ' 'ง ฉ' 'ง ช' 'ง ซ' 'ง ด' 'ง ต' 'ง ท' 'ง ป'\n",
            " 'ง พ' 'ง ย' 'ง ร' 'ง ล' 'ง ส' 'ง ห' 'ง า' 'ง ิ' 'ง เ' 'ง แ' 'ง ใ' 'จ'\n",
            " 'จ ด' 'จ น' 'จ บ' 'จ ร' 'จ ส' 'จ อ' 'จ ะ' 'จ ั' 'จ ุ' 'จ ้' 'ฉ' 'ช' 'ช อ'\n",
            " 'ช ั' 'ช ้' 'ซ' 'ซ ื' 'ซ ็' 'ญ' 'ญ ห' 'ฑ' 'ฑ ์' 'ด' 'ด ช' 'ด ต' 'ด พ'\n",
            " 'ด ย' 'ด ว' 'ด ส' 'ด ห' 'ด อ' 'ด า' 'ด ำ' 'ด ี' 'ด ื' 'ด ุ' 'ด ู' 'ด เ'\n",
            " 'ด ใ' 'ด ้' 'ต' 'ต ก' 'ต ร' 'ต อ' 'ต ะ' 'ต ั' 'ต า' 'ต ำ' 'ต ิ' 'ต ็'\n",
            " 'ต ่' 'ต ้' 'ถ' 'ถ ม' 'ถ ุ' 'ท' 'ท ั' 'ท า' 'ท ำ' 'ท ี' 'ท ้' 'น' 'น ก'\n",
            " 'น ข' 'น ค' 'น ช' 'น ซ' 'น ด' 'น ท' 'น น' 'น ป' 'น พ' 'น ม' 'น ร' 'น ส'\n",
            " 'น อ' 'น ะ' 'น ั' 'น า' 'น ำ' 'น ิ' 'น ี' 'น ื' 'น เ' 'น แ' 'น โ' 'น ไ'\n",
            " 'น ่' 'น ้' 'บ' 'บ ด' 'บ บ' 'บ ป' 'บ พ' 'บ ร' 'บ ล' 'บ อ' 'บ า' 'บ ิ'\n",
            " 'บ ุ' 'บ เ' 'บ ใ' 'บ ไ' 'ป' 'ป ก' 'ป ด' 'ป ผ' 'ป ร' 'ป ล' 'ป ั' 'ป ็' 'ผ'\n",
            " 'ผ ล' 'ผ ิ' 'ผ ้' 'พ' 'พ ก' 'พ ค' 'พ ง' 'พ ช' 'พ ด' 'พ น' 'พ ล' 'พ ส'\n",
            " 'พ อ' 'พ ั' 'พ เ' 'พ แ' 'พ ็' 'พ ้' 'ฟ' 'ฟ ร' 'ภ' 'ภ ั' 'ภ า' 'ม' 'ม ก'\n",
            " 'ม ข' 'ม ค' 'ม ด' 'ม ต' 'ม ร' 'ม ส' 'ม า' 'ม ี' 'ม ื' 'ม เ' 'ม แ' 'ม ใ'\n",
            " 'ม ่' 'ม ้' 'ย' 'ย ก' 'ย ค' 'ย ง' 'ย ด' 'ย ต' 'ย ท' 'ย น' 'ย บ' 'ย ม'\n",
            " 'ย ร' 'ย ว' 'ย ห' 'ย อ' 'ย ะ' 'ย า' 'ย ี' 'ย ุ' 'ย เ' 'ย ใ' 'ย ไ' 'ย ็'\n",
            " 'ย ่' 'ร' 'ร ก' 'ร ง' 'ร จ' 'ร ด' 'ร ร' 'ร ว' 'ร ส' 'ร อ' 'ร ะ' 'ร ั'\n",
            " 'ร า' 'ร ิ' 'ร ี' 'ร ุ' 'ร ู' 'ร ้' 'ล' 'ล อ' 'ล ะ' 'ล า' 'ล ิ' 'ล ี'\n",
            " 'ล ื' 'ล ู' 'ล ่' 'ล ้' 'ว' 'ว ก' 'ว จ' 'ว ม' 'ว ย' 'ว ส' 'ว ั' 'ว า'\n",
            " 'ว เ' 'ว โ' 'ว ่' 'ศ' 'ษ' 'ษ า' 'ส' 'ส ด' 'ส ม' 'ส ร' 'ส ว' 'ส อ' 'ส ะ'\n",
            " 'ส ั' 'ส ิ' 'ส ี' 'ส ึ' 'ส ุ' 'ส ่' 'ห' 'ห น' 'ห ม' 'ห ล' 'ห ว' 'ห ั'\n",
            " 'ห า' 'ห ้' 'อ' 'อ ก' 'อ ค' 'อ ง' 'อ ด' 'อ ท' 'อ น' 'อ บ' 'อ ป' 'อ ผ'\n",
            " 'อ พ' 'อ ม' 'อ ย' 'อ ร' 'อ ส' 'อ อ' 'อ ั' 'อ า' 'อ เ' 'อ แ' 'อ ใ' 'ะ'\n",
            " 'ะ ก' 'ะ ค' 'ะ ด' 'ะ ท' 'ะ น' 'ะ บ' 'ะ ร' 'ะ ส' 'ะ เ' 'ะ แ' 'ั' 'ั ก'\n",
            " 'ั ง' 'ั ญ' 'ั ฑ' 'ั ด' 'ั น' 'ั บ' 'ั ส' 'ั ่' 'ั ้' 'า' 'า ก' 'า ข'\n",
            " 'า ค' 'า ง' 'า ช' 'า ซ' 'า ด' 'า ต' 'า ท' 'า น' 'า ป' 'า ผ' 'า พ' 'า ม'\n",
            " 'า ย' 'า ร' 'า ว' 'า ส' 'า ห' 'า ะ' 'า เ' 'า แ' 'า ใ' 'า ไ' 'ำ' 'ำ ร'\n",
            " 'ำ ห' 'ำ เ' 'ำ แ' 'ำ ใ' 'ิ' 'ิ ก' 'ิ ง' 'ิ ด' 'ิ น' 'ิ แ' 'ิ ่' 'ี' 'ี ก'\n",
            " 'ี ค' 'ี ต' 'ี ป' 'ี ม' 'ี ย' 'ี ร' 'ี ส' 'ี ห' 'ี เ' 'ี แ' 'ี ่' 'ี ้'\n",
            " 'ึ' 'ึ ก' 'ึ ง' 'ื' 'ื น' 'ื อ' 'ื ่' 'ื ้' 'ุ' 'ุ ค' 'ุ ง' 'ุ ด' 'ุ ป'\n",
            " 'ุ ภ' 'ุ เ' 'ุ ่' 'ุ ้' 'ู' 'ู ก' 'ู ป' 'ู ส' 'ู ่' 'ู ้' 'เ' 'เ ก' 'เ ค'\n",
            " 'เ ง' 'เ จ' 'เ ช' 'เ ซ' 'เ ด' 'เ ต' 'เ น' 'เ ป' 'เ ย' 'เ ร' 'เ ล' 'เ ส'\n",
            " 'เ ห' 'แ' 'แ ก' 'แ ข' 'แ ต' 'แ ถ' 'แ น' 'แ บ' 'แ ป' 'แ พ' 'แ ย' 'แ ร'\n",
            " 'แ ล' 'โ' 'โ ฆ' 'โ ด' 'โ ป' 'โ อ' 'ใ' 'ใ จ' 'ใ ช' 'ใ ส' 'ใ ห' 'ไ' 'ไ ด'\n",
            " 'ไ ป' 'ไ ม' 'ไ ว' 'ไ ห' '็' '็ ก' '็ ค' '็ ง' '็ น' '็ บ' '็ ม' '่' '่ ง'\n",
            " '่ จ' '่ ด' '่ ต' '่ ถ' '่ น' '่ ม' '่ ย' '่ ส' '่ ห' '่ อ' '่ า' '่ เ'\n",
            " '่ ไ' '้' '้ ง' '้ ด' '้ ม' '้ ว' '้ ส' '้ อ' '้ า' '้ ำ' '้ แ' '้ ใ'\n",
            " '้ ไ' '๊' '๊ อ' '๋' '์']\n",
            "510\n",
            "{'เ': 428, 'ก': 3, 'ล': 265, 'ี': 391, 'ย': 225, 'ด': 96, 'ช': 85, 'อ': 310, 'บ': 163, 'ห': 302, 'ส': 289, 'ั': 342, '่': 479, 'ง': 51, 'ซ': 89, 'ื': 408, '้': 494, 'ท': 129, 'ไ': 466, 'น': 135, 'ค': 34, 'า': 353, 'เ ก': 429, 'ก ล': 14, 'ล ี': 270, 'ี ย': 397, 'ย ด': 229, 'ด ช': 97, 'ช อ': 86, 'อ บ': 317, 'ห ล': 305, 'ล อ': 266, 'อ ก': 311, 'ก ส': 16, 'ส ั': 296, 'ั ่': 351, '่ ง': 480, 'ง ซ': 57, 'ซ ื': 90, 'ื ้': 412, '้ อ': 500, 'อ ท': 315, 'ท ี': 133, 'ี ่': 403, '่ ไ': 493, 'ไ ห': 471, 'ห น': 303, 'น ไ': 160, 'ไ ด': 467, 'ด ้': 113, 'ค ้': 48, '้ า': 501, 'ิ': 384, 'ุ': 413, 'ภ': 206, 'พ': 189, 'ส ิ': 297, 'ิ น': 388, 'น ค': 138, 'า ด': 360, 'อ ย': 322, 'ย ค': 227, 'ค ุ': 45, 'ุ ภ': 418, 'ภ า': 208, 'า พ': 366, 'แ': 444, 'จ': 73, 'ะ': 331, 'ใ': 461, 'ต': 114, 'ร': 248, '็': 472, 'า แ': 375, 'จ ้': 83, '้ ง': 495, 'ะ ก': 332, 'ก ด': 9, 'ด ใ': 112, 'ใ ส': 464, 'ส ่': 301, '่ ต': 483, 'ต ะ': 118, 'ก ร': 13, 'ร ้': 264, 'า เ': 374, 'เ ซ': 434, 'ซ ็': 91, '็ ง': 475, 'ง เ': 70, 'เ ร': 440, 'ำ': 378, 'ม': 209, 'ย ่': 247, '่ า': 491, 'า ท': 362, 'ท ำ': 132, 'ำ แ': 382, 'แ บ': 450, 'บ บ': 165, 'น ี': 155, 'ี ้': 404, '้ แ': 503, 'แ ย': 453, '่ ม': 486, 'ม า': 217, 'า ก': 354, 'ผ': 185, 'ว': 275, 'ผ ิ': 187, 'ิ ด': 387, 'ด ห': 103, 'ห ว': 306, 'ว ั': 281, 'ั ง': 344, 'ง แ': 71, 'เ ต': 436, 'ต ก': 115, 'ก เ': 23, 'จ บ': 76, 'บ เ': 174, 'เ ย': 439, 'ย ก': 226, 'ร อ': 256, 'เ ล': 441, 'ล ิ': 269, 'ิ ก': 385, 'ก ก': 4, 'ฉ': 84, 'ป': 177, '์': 509, 'ก พ': 12, 'พ ั': 199, 'ง ฉ': 55, 'น ม': 146, 'ด พ': 99, 'พ อ': 198, 'อ ใ': 330, 'ใ จ': 462, 'เ ป': 438, 'ป ็': 184, '็ น': 476, 'น อ': 149, 'า ง': 357, 'ก ใ': 26, 'เ ส': 442, 'ส ร': 292, 'ว จ': 277, 'จ ะ': 80, 'ะ เ': 340, 'เ ค': 430, 'ค ล': 37, 'ย ร': 235, 'แ น': 449, 'น ะ': 150, 'ะ น': 336, 'น ำ': 153, 'ใ ช': 463, 'ช ้': 88, '้ ไ': 505, '้ ใ': 504, 'ไ ม': 469, 'ม ่': 223, '่ ส': 488, 'ง ส': 66, 'า ส': 371, 'ั ก': 343, 'ี เ': 401, 'เ ห': 443, 'น ื': 156, 'ื ่': 411, '่ อ': 490, 'ก า': 21, 'า ร': 369, 'ร ร': 253, 'อ ค': 312, 'ค อ': 40, 'ู': 422, 'ึ': 405, 'ส ี': 298, 'ค ว': 38, 'ว า': 282, 'า ม': 367, 'ม ร': 215, 'ร ู': 263, 'ู ้': 427, '้ ส': 499, 'ส ึ': 299, 'ึ ก': 406, 'ส ว': 293, 'ว ย': 279, 'ู ป': 424, '่ ด': 482, 'ด ี': 107, 'ย อ': 238, 'อ ด': 314, 'ด เ': 111, 'ย ี': 241, '่ ย': 487, 'ย ม': 234, 'ร า': 259, 'า ค': 356, 'ค า': 43, 'ห ม': 304, 'า ะ': 373, 'ะ ส': 339, 'ส ม': 291, 'บ อ': 170, 'ก ต': 10, 'ต ่': 124, 'ย เ': 243, 'ม ื': 219, 'ื อ': 410, 'อ น': 316, 'น ร': 147, 'บ ไ': 176, 'ไ ว': 470, 'ว ก': 276, 'ข': 28, 'ี ห': 400, 'น ้': 162, 'า น': 363, 'ุ ่': 420, 'ม ข': 211, 'ข า': 31, 'า ว': 370, 'ญ': 92, 'จ ั': 81, 'ั ด': 347, 'ด ส': 102, 'ส ะ': 295, 'ะ ด': 334, 'ด ว': 101, 'ข อ': 30, 'อ ง': 313, 'ง จ': 54, 'จ ร': 77, 'ร ิ': 260, 'ิ ง': 386, 'ข น': 29, 'น า': 152, 'ใ ห': 465, 'ง า': 68, '้ ด': 496, 'ฑ': 94, 'า ผ': 365, 'ง ร': 64, 'อ ส': 324, 'ย บ': 233, 'บ ร': 168, 'ร จ': 251, 'จ ุ': 82, 'ภ ั': 207, 'ั ฑ': 346, 'ฑ ์': 95, 'ค ั': 42, 'ั บ': 349, 'ง พ': 62, 'จ ส': 78, 'พ ด': 194, 'ี แ': 402, 'แ ข': 446, 'ข ็': 32, 'แ ร': 454, 'ร ง': 250, 'ย ง': 228, 'ง ด': 58, 'เ ด': 435, '็ ก': 473, 'พ ส': 197, 'ม เ': 220, 'ม ใ': 222, 'อ พ': 320, 'ั ส': 350, 'ส ด': 290, 'ด ุ': 109, 'ุ ด': 416, 'น เ': 157, 'ด ื': 108, 'น พ': 145, '๋': 508, 'ถ': 126, 'ฟ': 204, 'ย ใ': 244, 'ร ะ': 257, 'ก ะ': 19, 'แ พ': 452, 'พ ็': 202, '็ ค': 474, '่ ถ': 484, 'ถ ุ': 128, 'ุ ง': 415, 'ด ำ': 106, 'ำ ใ': 383, 'ย ะ': 239, 'ะ แ': 341, 'แ ถ': 448, 'ถ ม': 127, 'ม ส': 216, 'ป ร': 181, 'ร ก': 249, 'ต ร': 116, 'ร ว': 254, 'ส อ': 294, 'ล ู': 272, 'ู ก': 423, 'ก ค': 6, 'า ซ': 359, 'ฟ ร': 205, 'ร ี': 261, 'ี ป': 395, 'ร ั': 258, 'บ ป': 166, 'ร ุ': 262, 'โ': 456, 'ก ข': 5, 'ด ต': 98, 'ก น': 11, 'อ เ': 328, 'ย ว': 236, 'ว โ': 284, 'ย น': 232, 'น ส': 148, 'า ข': 355, 'ข ้': 33, 'ั ้': 352, '้ ว': 498, 'บ ุ': 173, 'ุ ค': 414, 'ค เ': 46, 'ย ห': 237, 'ห า': 308, 'า ย': 368, 'ย ท': 231, 'ะ บ': 337, 'บ พ': 167, 'ง ล': 65, 'ม ด': 213, 'ด อ': 104, 'อ า': 327, 'ย ุ': 242, 'พ ง': 192, 'ต อ': 117, 'น น': 143, 'ก ง': 7, 'อ ร': 323, 'พ ค': 191, 'ุ ้': 421, '้ ม': 497, 'ม ค': 212, 'ค ่': 47, 'ี ค': 393, 'ว ม': 278, 'ต ั': 119, 'า ต': 361, 'ต ้': 125, 'ง ก': 52, 'ร ส': 255, 'ะ ท': 335, 'ท า': 131, 'น ด': 141, 'ี ม': 396, 'ป ล': 182, 'น แ': 158, 'แ ป': 451, 'ก ั': 20, 'ุ ป': 417, 'ป ด': 179, 'า ใ': 376, 'แ ล': 455, 'ล ้': 274, 'ก แ': 24, 'พ ้': 203, 'า ห': 372, 'ห ้': 309, 'ว ส': 280, 'ง ต': 59, 'ย ็': 246, 'เ ช': 433, 'ค ด': 35, 'น ป': 144, 'ป ก': 178, 'ต ิ': 122, 'ม ี': 218, 'ป ั': 183, 'ั ญ': 345, 'ญ ห': 93, 'น ั': 151, 'ว ่': 285, 'ป ผ': 180, '็ บ': 477, 'บ ด': 164, 'ว เ': 283, 'ต ็': 123, '็ ม': 478, 'ล ่': 273, 'ด า': 105, 'พ แ': 201, 'ง ท': 60, 'ท ้': 134, 'ล า': 268, '่ ห': 489, 'ง ย': 63, 'ฆ': 49, 'ษ': 287, 'โ ฆ': 457, 'ฆ ษ': 50, 'ษ า': 288, 'ี ส': 399, 'ค ร': 36, 'ส ุ': 300, 'ะ ค': 333, 'ค ะ': 41, '่ จ': 481, '่ เ': 492, 'ี ร': 398, 'บ ใ': 175, 'จ ด': 74, 'พ น': 195, 'น ท': 142, 'ด ู': 110, 'บ า': 171, 'ย า': 240, 'โ อ': 460, 'า ไ': 377, 'ะ ร': 338, 'ม แ': 221, 'น ่': 161, '่ น': 485, 'ล ื': 271, 'ก ซ': 8, 'อ อ': 325, 'อ ั': 326, 'ั น': 348, 'ง ช': 56, 'ย ไ': 245, 'ค ื': 44, 'ื น': 409, 'เ ง': 431, 'ง ิ': 69, 'ไ ป': 468, 'ก อ': 18, 'ู ส': 425, 'เ จ': 432, 'จ อ': 79, 'ย ต': 230, 'ต ำ': 121, 'ำ ห': 380, 'น ิ': 154, 'ก ว': 15, 'ุ เ': 419, 'แ ต': 447, 'ก ห': 17, 'ห ั': 307, 'อ ผ': 319, 'บ ิ': 172, '้ ำ': 502, 'ี ต': 394, 'ิ ่': 390, 'ม ้': 224, 'ผ ล': 186, 'อ แ': 329, 'ศ': 286, 'น ข': 137, 'า ป': 364, 'ต า': 120, 'ม ก': 210, 'ก ำ': 22, 'พ ช': 193, 'ช ั': 87, 'ร ด': 252, 'พ เ': 200, 'จ น': 75, 'ก โ': 25, 'โ ด': 458, 'ด ย': 100, 'พ ก': 190, 'o': 1, 'k': 0, 'o k': 2, '๊': 506, 'น ช': 139, '๊ อ': 507, 'อ ป': 318, 'ึ ง': 407, 'พ ล': 196, 'ก ๊': 27, 'แ ก': 445, 'ง ใ': 72, 'น ก': 136, 'ี ก': 392, 'ท ั': 130, 'โ ป': 459, 'ำ เ': 381, 'ง ค': 53, 'น ซ': 140, 'ำ ร': 379, 'ม ต': 214, 'ง ป': 61, 'อ ม': 321, 'น โ': 159, 'เ น': 437, 'ผ ้': 188, 'ง ห': 67, 'า ช': 358, 'ล ะ': 267, 'ู ่': 426, 'บ ล': 169, 'ค ส': 39, 'ิ แ': 389}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7."
      ],
      "metadata": {
        "id": "i1B5KUCM68xF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train,y_test = train_test_split(document2,label2,test_size=0.2)\n",
        "# print(X_train.shape,X_test.shape)\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")\n",
        "print(X_test)\n",
        "X_train = vectorizer.transform(X_train).toarray()\n",
        "X_test = vectorizer.transform(X_test).toarray()\n",
        "print(len(X_train[0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fcNC9WmR4P3S",
        "outputId": "fbafb58a-4f34-4ff3-ee51-ff5fee78bf46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 102\n",
            "Test set size: 26\n",
            "['รายการไม่ดี ที่จับไม่ดีและสั้น', 'ส่งของไว ห่อพัสดุดี  ของใช้งานเยี่ยม', 'ถูกกว่าในห้างเยอะเลยครับ ภาพชัด สินค้าใหม่ พนักงานบริการดีมาก สั่งสินค้ากับลาซาด้าไม่เคยผิดหวังเลยครับ', 'เสียงดี ส่งเร็ว ราคานี้คุ้มครับ ', 'เห็นแล้วรู้สึกแย่ ไม่มั่นใจในสินค้าร้านนี้', 'สินค้าไม่มีคุณภาพสายกางเกงไม่เท่ากัน', 'ผ้านิ่ม เด้งๆ ดีกว่าที่คิดไว้ ชอบคะ', 'ส่งของไวมาก แต่ราคาขึ้นลงบ่อยมา ต้องเข้ามาเช็คราคาบ่อยๆ ว่าวันไหนจะราคาถูก แต่คุ้มแน่นอนค่ะ เลือกซื้ออันนี้ไม่ผิดหวังค่ะ', 'สินค้าใช้ดีสีสดใช้จนถึงทุกวันนี้', 'แย่มากเลย นมใกล้หมดอายุ ครั้งนี้ครั้งสุดท้ายนะคะที่จะสั่ง', 'สมราคาค่ะ ภาพชัดเจน เทียบกับยี่ห้ออื่นราคาถูกกว่า', 'ซื้อมายังไม่ทันเล่นเลยพังซะแล้ว', 'วัสดุค่อนข้างดีนับว่าคุ้มราคาครับ', 'รับประทานดีอยู่นะครับ มองเห็นความเปลี่ยนแปลงของร่างกาย ทานแล้วรู้สึกว่าดีนะ', 'เนื้อผ้าดีมากๆๆๆๆเกินราคา กำลังจะสั่งเพิ่มอีก ช้าหน่อยแต่ได้มาไม่ผิดหวังเลยค่ะ', 'สวยค่ะ เหมือนในรูปเลย ชอบค่ะ ส่งของไวมากก', 'ได้รับสินค้าเร็วค่ะ และสินค้าก็มีคุณภาพ สวมใส่สบายตัวมากๆๆ เลยค่ะ', 'แย่มากๆๆๆๆ ไม่ส่งของแถมมาให้ตามที่โฆษณา ', 'สรุปแพงกว่าท้องตลาดคะแย่มากเสียความ', 'การส่งของแย่มาก ขนาดตะโกนว่ารอเดี๋ยว ยังโยนสินค้าข้ามรั้ว ถ้าโน้ตบุคเสียหายจะทำยังไง', 'ซื้อแล้วผิดหวังสินค้าไม่มีคุณภาพ', 'แย่มากเสียดายเงิน', 'แย่มาก รูปดูสวยหรูดีนะ แต่มาเจอของจริงนี่แย่สุดๆ สินค้าไม่สมกับราคาเลย ', 'จอใหญ่มาก คุณภาพเสียง ชัดเจนดีมาก โดยรวมแล้วคุ้มค่ามาก', 'เสื้อสวยถูกใจค่ะส่งเร็วทันใจดี', 'สวยมาใช้งานง่ายมากที่สำคัญส่งเร็วมาก']\n",
            "510\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "clf = CategoricalNB()\n",
        "clf.fit(X_train,y_train)\n",
        "y_label = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_label, y_test)\n",
        "print(accuracy)\n",
        "print(y_label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ox2WoIkgxEFC",
        "outputId": "ce412738-3099-4870-d427-59b7bc072bfd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.6153846153846154\n",
            "['neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg'\n",
            " 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg' 'neg'\n",
            " 'neg' 'neg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8."
      ],
      "metadata": {
        "id": "ZRernt_fHozg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bpemb\n",
        "from bpemb import BPEmb\n",
        "bpemb_th = BPEmb(lang=\"th\")\n",
        "# bpemb_th.encode(\"โชคดีจริง\")\n",
        "def bpemb_tokenizer(text):\n",
        "  prunct =  [',','?','.',';',':','!','ๆ','ฯ']\n",
        "  clean = [x for x in text if x not in prunct]\n",
        "  clean = ''.join(clean)\n",
        "\n",
        "  clean = [normalize(x) for x in clean]\n",
        "  clean = ''.join(clean)\n",
        "  return bpemb_th.encode(clean)\n",
        "\n",
        "vectorizerBPE = TfidfVectorizer(stop_words=thai,\n",
        "                             tokenizer=bpemb_tokenizer,)\n",
        "                            #  ngram_range=(1,2),\n",
        "                            #  min_df=2)\n",
        "vectorizerBPE.fit(document2)\n",
        "vectorizerBPE.vocabulary_\n",
        "terms = vectorizerBPE.get_feature_names_out()\n",
        "doc_arrayBPE = vectorizerBPE.transform(document2).toarray()\n",
        "print(doc_arrayBPE.shape)\n",
        "print(doc_arrayBPE)\n",
        "print(terms)\n",
        "print(len(vectorizerBPE.vocabulary_))\n",
        "print(vectorizerBPE.vocabulary_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f3UX8MsEItZf",
        "outputId": "bac8606d-c39f-4f6d-ef0a-ef10d61d63d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: bpemb in /usr/local/lib/python3.10/dist-packages (0.3.5)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (from bpemb) (4.3.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bpemb) (1.26.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from bpemb) (2.32.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from bpemb) (0.2.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from bpemb) (4.66.5)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim->bpemb) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim->bpemb) (7.0.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->bpemb) (2024.8.30)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open>=1.8.1->gensim->bpemb) (1.16.0)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:521: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:406: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ก', 'กบ', 'กระ', 'กระท', 'กล', 'กวน', 'กอน', 'กอบ', 'กาล', 'ข', 'ขน', 'ขา', 'ค', 'คณ', 'คน', 'คร', 'คอ', 'คอย', 'ง', 'งบ', 'งาน', 'จ', 'ฉ', 'ฉะ', 'ช', 'ชน', 'ชนก', 'ชา', 'ซ', 'ญ', 'ฏ', 'ด', 'ดก', 'ดง', 'ดน', 'ดอย', 'ต', 'ตก', 'ตอ', 'ตอง', 'ถ', 'ถา', 'ท', 'ทน', 'ทาน', 'ทาย', 'น', 'นก', 'นน', 'นอน', 'นา', 'บ', 'บาย', 'ป', 'ปวง', 'ผ', 'ผม', 'ฝ', 'พ', 'พาะ', 'ม', 'มง', 'มน', 'มวล', 'มอ', 'มาจาก', 'มาย', 'ย', 'ยง', 'ยน', 'ยะ', 'ยายาม', 'ร', 'รก', 'รง', 'รณ', 'รด', 'รบ', 'รม', 'รอง', 'ระ', 'ระยะเวลา', 'ล', 'ลา', 'ลาย', 'ว', 'วก', 'วง', 'วด', 'วน', 'วบ', 'วย', 'วา', 'วาง', 'วาน', 'ศก', 'สง', 'สด', 'สน', 'สบ', 'สม', 'สมควร', 'สร', 'สาว', 'ห', 'หง', 'หนา', 'หมาย', 'หร', 'หลง', 'หา', 'หาร', 'อ', 'อก', 'อง', 'อด', 'อต', 'อท', 'อน', 'อม', 'อย', 'อว', 'อะ', 'อาท', 'ะ', 'า', 'าก', 'าง', 'าท', 'าน', 'าย', 'ายนอก', 'าว', 'าส', 'เ', 'เกน', 'เกา', 'เจ', 'เช', 'เชน', 'เด', 'เต', 'เถ', 'เน', 'เป', 'เปน', 'เผย', 'เพ', 'เม', 'เร', 'เวลา', 'เส', 'เสร', 'เห', 'เหน', 'เหม', 'เหมาะ', 'แ', 'แค', 'แจ', 'แด', 'แต', 'แตน', 'แท', 'แนะ', 'แปลง', 'แม', 'แมน', 'แล', 'แหง', 'แหล', 'โง', 'โนน', 'ใ', 'ใจ', 'ใช', 'ใด', 'ให', 'ใหญ', 'ใหม', 'ไ', 'ไข', 'ได', 'ไปทาง', 'ไม', 'ไว', 'ไหม', '▁', '▁ก', '▁กระ', '▁กล', '▁การ', '▁กํา', '▁กําหนด', '▁ข', '▁ขณะ', '▁ขน', '▁ขอ', '▁ของ', '▁ค', '▁คง', '▁คณ', '▁คร', '▁ควร', '▁ความ', '▁คอน', '▁คะ', '▁คํา', '▁ง', '▁จ', '▁จง', '▁จน', '▁จบ', '▁จะ', '▁จา', '▁จาก', '▁จํา', '▁ฉ', '▁ช', '▁ชา', '▁ชาว', '▁ซ', '▁ณ', '▁ด', '▁ต', '▁ตลอด', '▁ตลอดจน', '▁ตาม', '▁ถ', '▁ท', '▁ทรง', '▁ทา', '▁ทาง', '▁ทํา', '▁น', '▁นก', '▁นอก', '▁นอกจาก', '▁นะ', '▁นา', '▁นาง', '▁นาย', '▁นํา', '▁บ', '▁บน', '▁บาง', '▁ป', '▁ปร', '▁ประ', '▁ประกอบ', '▁ประมาณ', '▁ผ', '▁ผล', '▁พ', '▁พง', '▁พบ', '▁พร', '▁พวก', '▁พวกเขา', '▁พอ', '▁พา', '▁ภ', '▁ภาค', '▁ภาย', '▁ภายใน', '▁ม', '▁มา', '▁มาก', '▁ย', '▁ยก', '▁ยาว', '▁ร', '▁รวม', '▁ระ', '▁ราย', '▁ล', '▁ลง', '▁วา', '▁ส', '▁สง', '▁สน', '▁สม', '▁สวน', '▁สา', '▁สามารถ', '▁สํา', '▁หน', '▁หม', '▁หล', '▁หลาย', '▁หาก', '▁อ', '▁อน', '▁ออก', '▁อะ', '▁อาจ', '▁เ', '▁เก', '▁เข', '▁เขา', '▁เคย', '▁เฉ', '▁เช', '▁เด', '▁เต', '▁เท', '▁เธอ', '▁เน', '▁เป', '▁เปล', '▁เพ', '▁เพราะ', '▁เม', '▁เย', '▁เร', '▁เรา', '▁เล', '▁เส', '▁เสม', '▁เห', '▁เหน', '▁เหล', '▁เอา', '▁แ', '▁แก', '▁แค', '▁แคว', '▁แต', '▁แท', '▁แบบ', '▁แม', '▁แมน', '▁แล', '▁และ', '▁แสดง', '▁แหล', '▁โดย', '▁โต', '▁ใน', '▁ไ', '▁ได', '▁ไป', '▁ไม', '▁ไร', '▁ไว', '\\ufeff'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 378)\n",
            "[[0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]\n",
            " ...\n",
            " [0.         0.         0.15827222 ... 0.         0.         0.        ]\n",
            " [0.17468144 0.         0.0760336  ... 0.         0.         0.        ]\n",
            " [0.         0.         0.         ... 0.         0.         0.        ]]\n",
            "['00' 'ok' 'ก' 'กด' 'กบ' 'กร' 'กรด' 'กระ' 'กรา' 'กล' 'กลอง' 'กว' 'กวน'\n",
            " 'กอ' 'กอง' 'กอน' 'กอบ' 'กะ' 'กาง' 'กาย' 'การทํางาน' 'กําหนด' 'ข' 'ขน'\n",
            " 'ขนาด' 'ขา' 'ขาม' 'ขาย' 'ขาว' 'ค' 'คณ' 'คน' 'คบ' 'คม' 'คร' 'คล' 'คอ'\n",
            " 'คอน' 'คอม' 'คอย' 'คะแนน' 'คา' 'คาด' 'คาท' 'คาน' 'คาม' 'คาร' 'คาส' 'ง'\n",
            " 'งาน' 'จ' 'จบ' 'จอ' 'จะทํา' 'ฉ' 'ฉก' 'ช' 'ชด' 'ชน' 'ชอบ' 'ชา' 'ซ' 'ซอ'\n",
            " 'ซอง' 'ซา' 'ญ' 'ณฑ' 'ด' 'ดง' 'ดน' 'ดม' 'ดร' 'ดอย' 'ดา' 'ดํา' 'ต' 'ตก'\n",
            " 'ตร' 'ตรวจสอบ' 'ตลาด' 'ตอ' 'ตอง' 'ตอน' 'ตะ' 'ตํา' 'ถ' 'ถา' 'ถาม' 'ท' 'ทน'\n",
            " 'ทบ' 'ทร' 'ทะ' 'ทาน' 'ธ' 'น' 'นก' 'นคร' 'นรา' 'นว' 'นา' 'บ' 'บก' 'บท'\n",
            " 'บบ' 'บร' 'บรร' 'บรา' 'บล' 'บอย' 'บาท' 'บาย' 'ป' 'ปก' 'ปร' 'ปรก' 'ประ'\n",
            " 'ประก' 'ประกาศ' 'ประทาน' 'ปลอด' 'ปลอม' 'ผ' 'ผา' 'ฝา' 'พ' 'พง' 'พลาด'\n",
            " 'พลาส' 'พอใจ' 'พาส' 'ฟ' 'ภ' 'ภาพ' 'ภาพของ' 'ม' 'มน' 'มร' 'มอ' 'มาย' 'ย'\n",
            " 'ยง' 'ยน' 'ยม' 'ยะ' 'ร' 'รง' 'รถ' 'รบ' 'รส' 'รอ' 'รอน' 'รอบ' 'รอย' 'ระบบ'\n",
            " 'ระเบ' 'รา' 'ราคา' 'ราง' 'ราน' 'ราะ' 'รํา' 'ล' 'ลบ' 'ลวง' 'ลา' 'ว' 'วก'\n",
            " 'วง' 'วจ' 'วด' 'วน' 'วย' 'วา' 'วาด' 'ศ' 'ษ' 'ส' 'สก' 'สง' 'สด' 'สถ' 'สน'\n",
            " 'สม' 'สร' 'สว' 'สวม' 'สวย' 'สอง' 'สะดวก' 'สาย' 'สํา' 'ห' 'หก' 'หนา' 'หร'\n",
            " 'หล' 'หลอก' 'หอ' 'หา' 'หาคม' 'หาง' 'หาย' 'อ' 'อก' 'อง' 'อด' 'อต' 'อน'\n",
            " 'อบ' 'อป' 'อฟ' 'อม' 'อย' 'อล' 'อส' 'ออ' 'ออกมา' 'ออน' 'อะ' 'อาย' 'อาหาร'\n",
            " 'ะ' 'า' 'าก' 'าง' 'าด' 'าท' 'าน' 'านา' 'าม' 'ามา' 'ามาก' 'าย' 'ายน' 'าร'\n",
            " 'าลง' 'าว' 'าส' 'เ' 'เก' 'เกน' 'เข' 'เค' 'เคร' 'เคล' 'เง' 'เจ' 'เจน'\n",
            " 'เจอ' 'เช' 'เซ' 'เด' 'เดน' 'เต' 'เถ' 'เท' 'เน' 'เป' 'เปน' 'เปล' 'เพ' 'เม'\n",
            " 'เย' 'เร' 'เล' 'เลก' 'เลน' 'เวล' 'เส' 'เสร' 'เหน' 'เหม' 'เหมาะ' 'เหมาะสม'\n",
            " 'เหย' 'เหล' 'เอ' 'แกง' 'แกะ' 'แข' 'แจ' 'แต' 'แตก' 'แถ' 'แท' 'แน' 'แนน'\n",
            " 'แนะนํา' 'แป' 'แปลง' 'แผล' 'แพ' 'แพง' 'แพร' 'แฟน' 'แม' 'แย' 'แยก' 'แรง'\n",
            " 'แล' 'แส' 'แหง' 'โก' 'โค' 'โฆ' 'โฆษณา' 'โจร' 'โดยรวม' 'โน' 'โป' 'โปร'\n",
            " 'โยน' 'โอ' 'ใ' 'ใจ' 'ใช' 'ใด' 'ใบ' 'ใส' 'ให' 'ใหญ' 'ใหม' 'ไ' 'ได' 'ไปตาม'\n",
            " 'ไฟ' 'ไม' 'ไว' 'ไหม' 'ไหล' 'ไหว' 'ํา' 'ําร' '▁' '▁การ' '▁ขน' '▁ค' '▁คณ'\n",
            " '▁ง' '▁งาน' '▁จ' '▁จากการ' '▁ชอบ' '▁ชา' '▁ซ' '▁ด' '▁ต' '▁ถ' '▁ผ' '▁พ'\n",
            " '▁ม' '▁ยอด' '▁ร' '▁รา' '▁รายการ' '▁ว' '▁ส' '▁สง' '▁สน' '▁สม' '▁หม' '▁หล'\n",
            " '▁เ' '▁เกล' '▁เน' '▁เป' '▁เส' '▁เหน' '▁แ' '▁แบ' '▁แพ' '▁แรง' '▁โอ' '▁ได'\n",
            " '▁ไม' '☺' '😢']\n",
            "378\n",
            "{'▁เกล': 364, 'ย': 140, 'ด': 67, 'ชอบ': 59, 'หลอก': 197, 'ให': 320, 'สง': 179, 'ซอ': 62, 'ท': 88, 'ได': 324, 'ไม': 327, 'ม': 135, 'สน': 182, 'คา': 41, '▁สน': 359, 'คาด': 42, 'อย': 213, 'คณ': 30, 'ภาพ': 133, 'แจ': 281, 'ง': 48, 'ขน': 23, 'วา': 173, 'อะ': 219, 'กด': 3, 'ใส': 319, 'ตะ': 83, 'กรา': 8, 'เถ': 255, 'เซ': 251, 'เร': 264, '▁': 334, 'า': 223, 'นก': 96, 'บ': 101, 'อก': 204, 'แย': 297, '▁ค': 337, 'อ': 203, 'เ': 239, 'บบ': 104, 'ผ': 122, 'ห': 192, 'วง': 168, 'เย': 263, 'สด': 180, 'ฝา': 124, 'เต': 254, 'ก': 2, 'น': 95, 'คร': 34, 'เด': 252, 'ว': 166, 'จบ': 51, '😢': 377, '▁สง': 358, 'ชา': 60, 'รอน': 151, 'าน': 228, 'เลก': 266, 'กอ': 13, '▁แ': 369, 'พง': 126, 'ฉ': 54, 'พอใจ': 129, 'เปน': 259, 'าง': 225, 'ใบ': 318, 'เสร': 270, 'จ': 50, 'ไหว': 331, 'เคล': 245, 'ร': 145, '▁ไม': 375, 'แนะนํา': 288, 'ใช': 316, 'วน': 171, 'แล': 300, 'สก': 178, 'เหน': 271, 'กบ': 4, 'รอ': 150, 'คอย': 39, '▁เส': 367, 'รส': 149, 'สวย': 187, 'แต': 282, 'ป': 112, '▁ยอด': 352, 'ยม': 143, 'ราคา': 157, 'เหมาะสม': 274, 'ตอ': 80, '▁ส': 357, 'วย': 172, 'เหม': 272, 'อน': 208, 'ไว': 328, 'ขาว': 28, '▁จ': 341, 'สะดวก': 189, 'รง': 146, 'ขนาด': 24, 'ใหญ': 321, 'กว': 11, 'าท': 227, 'ค': 29, 'งาน': 49, '▁ชอบ': 343, 'คาม': 45, 'าก': 224, 'ทร': 91, 'อส': 215, 'ยง': 141, 'บรร': 106, 'ภ': 132, 'ณฑ': 66, 'คบ': 32, 'คาส': 47, 'แข': 280, 'แรง': 299, 'เส': 269, 'วด': 170, '▁รา': 354, 'ภาพของ': 134, 'าย': 233, 'หอ': 198, 'พ': 125, 'กร': 5, 'ใจ': 315, 'กระ': 7, 'เป': 258, 'กะ': 17, 'คาท': 43, 'แพ': 292, 'ถ': 85, 'ดํา': 74, 'ข': 22, 'ยะ': 144, 'แถ': 284, 'ปรก': 115, 'ตรวจสอบ': 78, 'กอน': 15, 'อล': 214, 'อฟ': 211, 'ปร': 114, '▁การ': 335, 'โก': 303, 'นว': 99, 'าร': 235, 'โยน': 312, 'ขาม': 26, 'ถา': 86, 'โน': 309, 'ต': 75, 'หาย': 202, 'จะทํา': 53, 'ไ': 323, 'รถ': 147, 'ระบบ': 154, '▁ผ': 349, 'ลบ': 163, '▁หม': 361, 'อาย': 220, 'เอ': 277, 'าม': 230, 'าลง': 236, 'ขาย': 27, 'แพง': 293, 'ช': 56, 'ามาก': 232, 'ตอน': 82, '▁ได': 374, 'รบ': 148, 'สาย': 190, 'กาง': 18, 'เก': 240, 'เท': 256, '▁ชา': 344, 'รํา': 161, 'ญ': 65, '▁คณ': 338, 'คม': 33, 'สวม': 186, 'ตอง': 81, '▁ร': 353, 'ประทาน': 119, 'ดอย': 72, 'เปล': 260, 'ยน': 142, 'แปลง': 290, 'ราง': 158, 'กาย': 19, 'ทาน': 93, 'ดน': 69, 'ะ': 222, 'เหมาะ': 273, 'บรา': 107, 'คาน': 44, 'สร': 184, 'วาด': 174, 'ใ': 314, 'หล': 196, 'หาง': 201, 'ราน': 159, 'ปก': 113, 'หา': 199, '▁ว': 356, 'คอน': 37, 'สว': 185, 'แพร': 294, 'ลา': 165, 'เหล': 276, 'อต': 207, 'แม': 296, 'อง': 205, 'ตลาด': 79, 'โฆษณา': 306, '▁งาน': 340, 'สม': 183, 'เล': 265, 'กล': 9, 'นคร': 97, 'ายน': 234, 'รอบ': 152, 'วจ': 169, 'รา': 156, 'บท': 103, '▁ด': 346, 'านา': 229, 'ทน': 89, 'มอ': 138, 'ใหม': 322, 'นา': 100, 'ามา': 231, 'อบ': 209, 'โอ': 313, 'เค': 243, 'สํา': 191, 'บอย': 109, 'เข': 242, 'เช': 250, 'าว': 237, 'แนน': 287, 'ซ': 61, 'ออน': 218, 'ทะ': 92, 'อาหาร': 221, 'บร': 105, 'าส': 238, 'คอ': 36, 'คน': 31, 'เง': 246, 'หร': 195, 'เจอ': 249, 'รอย': 153, 'ตํา': 84, 'แตก': 283, 'หก': 193, '▁ซ': 345, 'แหง': 302, '▁ต': 347, 'โค': 304, 'ตร': 77, 'แยก': 298, 'ปลอด': 120, 'ระเบ': 155, 'ดม': 70, 'ไหม': 329, 'ประ': 116, 'ไฟ': 326, 'แผล': 291, 'แส': 301, 'ส': 177, 'กวน': 12, 'ประกาศ': 118, 'กําหนด': 21, '▁ถ': 348, 'ชด': 57, 'ซา': 64, 'ดา': 73, '▁แรง': 372, 'หนา': 194, 'จอ': 52, 'เจน': 248, 'โดยรวม': 308, '▁พ': 350, 'พาส': 130, 'วก': 167, '▁โอ': 373, 'สอง': 188, 'ok': 1, 'เดน': 253, 'อป': 210, 'คะแนน': 40, 'พลาส': 128, 'ตก': 76, 'กอง': 14, 'แกง': 278, '▁แพ': 371, 'กลอง': 10, 'ฉก': 55, 'ทบ': 90, 'ขา': 25, 'ดง': 68, 'โปร': 311, '▁แบ': 370, 'ประก': 117, '▁เหน': 368, 'มน': 136, 'คาร': 46, 'ออกมา': 217, 'เวล': 268, 'ํา': 332, 'การทํางาน': 20, 'ดร': 71, '▁หล': 362, 'ลวง': 164, 'ปลอม': 121, 'โจร': 307, '▁เน': 365, 'าด': 226, 'โป': 310, '▁ง': 339, '▁สม': 360, 'บก': 102, 'เคร': 244, 'ไหล': 330, 'ล': 162, 'เจ': 247, '☺': 376, '▁เ': 363, 'กรด': 6, 'คล': 35, 'มาย': 139, 'ไปตาม': 325, 'โฆ': 305, 'ษ': 176, 'เม': 262, 'ใด': 317, 'บล': 108, 'กอบ': 16, 'ชน': 58, 'เกน': 241, 'ฟ': 131, 'สถ': 181, 'ศ': 175, 'บาท': 110, 'แป': 289, 'ําร': 333, 'แกะ': 279, 'อม': 212, 'เลน': 267, 'ผา': 123, 'อด': 206, 'คอม': 38, 'นรา': 98, 'เพ': 261, 'เหย': 275, 'แน': 286, '▁จากการ': 342, 'แท': 285, 'แฟน': 295, 'หาคม': 200, '▁ม': 351, 'พลาด': 127, 'ออ': 216, 'ธ': 94, 'บาย': 111, 'ถาม': 87, '▁เป': 366, 'ราะ': 160, '▁ขน': 336, 'มร': 137, 'เน': 257, 'ซอง': 63, '00': 0, '▁รายการ': 355}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9."
      ],
      "metadata": {
        "id": "uJAISEiDHoEw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train,y_test = train_test_split(document2,label2,test_size=0.2)\n",
        "# print(X_train.shape,X_test.shape)\n",
        "print(f\"Training set size: {len(X_train)}\")\n",
        "print(f\"Test set size: {len(X_test)}\")\n",
        "print(X_test)\n",
        "X_train = vectorizerBPE.transform(X_train).toarray()\n",
        "X_test = vectorizerBPE.transform(X_test).toarray()\n",
        "print(len(X_train[0]))\n",
        "from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.metrics import accuracy_score\n",
        "clf1 = BernoulliNB()\n",
        "clf1.fit(X_train,y_train)\n",
        "y_label = clf1.predict(X_test)\n",
        "accuracy = accuracy_score(y_label, y_test)\n",
        "print(accuracy)\n",
        "print(y_label)\n",
        "print(clf1.classes_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpwQwsPtR1-2",
        "outputId": "dc2ecfc5-f4ba-46c4-ffb5-84708444d1e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training set size: 102\n",
            "Test set size: 26\n",
            "['รายการไม่ดี ที่จับไม่ดีและสั้น', 'ผ้านิ่ม เด้งๆ ดีกว่าที่คิดไว้ ชอบคะ', 'แย่มากเลย นมใกล้หมดอายุ ครั้งนี้ครั้งสุดท้ายนะคะที่จะสั่ง', 'สินค้าคุณภาพดี แข็งแรง เสียงดี เด็กๆ ชอบ และยังส่งเร็วด้วยค่ะ', 'อย่าขายเลย ยกเลิกโปรนี้เถอะ เสียความรู้สึก ดูมาหลายเดือนละ', 'เสียความรู้สึกค่ะมาไม่ตรงที่สั่ง', 'ใช้เดือนเดียวพังแย่ๆมากๆ', 'ใช้ดียังไม่มีปัญหาอะไรค่ะชอบมาก', 'ใช้ดีส่งของไว มากเจ้านี้  วัสดุคุณภาพจริงจริง', 'ได้รับของเร็วมาก กระทะร้อนเร็ว ทำอาหารได้หลายอย่างเลยค่ะ ชอบมาก', 'สมราคาค่ะ ภาพชัดเจน เทียบกับยี่ห้ออื่นราคาถูกกว่า', 'เสียความรู้สึกอย่างมาก สวยแต่ในรูปใส่ได้ครั้งเดียว ไม่ดี', 'ผิดหวัง ลบไม่ออก', 'สวยมาใช้งานง่ายมากที่สำคัญส่งเร็วมาก', 'แย่มาก บิดน้ำไม่แห้ง เสียดายตังมาก', 'สินค้ามีตำหนิ แย่มากๆ ไม่ไหวๆเลย ถ้ามีตำหนิก็บอกด้วยครับ จะได้ทำใจก่อนซื้อ', 'สินค้าแพคอย่างดี ที่สำคัญส่งขอเร็วมาก คิดว่าจะได้ช้าเสียอีก', 'สเป็คถือว่าโอเครเลยคับ ไหลลื่นดีไม่มีสดุด สมกับราคา และคุ้มค่ามากๆเลย', 'วัสดุค่อนข้างดีนับว่าคุ้มราคาครับ', 'คือเเบบผิดหวังมาก เเย่ที่สุดได้ของมาฝาเเตก เเตกนิดหน่อยไม่ว่าเเตกเยอะมาก ครั้งเดียวพอจบเเยก😢', 'ส่งช้าจัง รอนานมาก ยกเลิกก้อไม่ได้', 'สินค้าไม่เหมือนในรูป ผิดหวังมาก เย็บไม่ดีเลย', 'แพ็คสินค้าดี สินค้าคุณภาพ สมราคา แฟนประทับใจครับ', 'ช้าสุดๆรอจนรำคาญละ', 'พกพาสะดวก ได้ของเร็ว', 'แย่มากๆสั่งของจ่ายเงิน แต่ไม่ได้ของ!']\n",
            "378\n",
            "0.8461538461538461\n",
            "['neg' 'pos' 'neg' 'neg' 'neg' 'neg' 'neg' 'pos' 'pos' 'pos' 'pos' 'neg'\n",
            " 'neg' 'pos' 'neg' 'neg' 'neg' 'pos' 'pos' 'neg' 'pos' 'neg' 'pos' 'pos'\n",
            " 'pos' 'neg']\n",
            "['neg' 'pos']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10."
      ],
      "metadata": {
        "id": "4M2hs_w_6vEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_doc = ['สินค้าตรงปกส่งไว','ไม่ไหวอย่างแรงไร้สาระ']\n",
        "test_doc = vectorizerBPE.transform(test_doc).toarray()\n",
        "negative,positive = clf1.predict_proba(test_doc)[0]\n",
        "print(negative)\n",
        "print(positive)\n",
        "print(clf1.predict_proba(test_doc))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGRSJhIa6x_o",
        "outputId": "781d86b3-f4b2-4414-bccc-97bf3fefb7be"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.07726960263357859\n",
            "0.9227303973664206\n",
            "[[0.0772696  0.9227304 ]\n",
            " [0.97167621 0.02832379]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mYxfclYdgOEL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}